{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120,"sourceType":"datasetVersion","datasetId":55}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T17:39:46.723067Z","iopub.execute_input":"2024-06-26T17:39:46.724406Z","iopub.status.idle":"2024-06-26T17:39:46.734567Z","shell.execute_reply.started":"2024-06-26T17:39:46.724356Z","shell.execute_reply":"2024-06-26T17:39:46.733242Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/enron-email-dataset/emails.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport string\nimport warnings\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline    \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, classification_report, accuracy_score, f1_score\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:39:46.736871Z","iopub.execute_input":"2024-06-26T17:39:46.737898Z","iopub.status.idle":"2024-06-26T17:39:46.751127Z","shell.execute_reply.started":"2024-06-26T17:39:46.737856Z","shell.execute_reply":"2024-06-26T17:39:46.750192Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/enron-email-dataset/emails.csv\", nrows = 10000)\ndf.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:39:46.763406Z","iopub.execute_input":"2024-06-26T17:39:46.764136Z","iopub.status.idle":"2024-06-26T17:39:47.421342Z","shell.execute_reply.started":"2024-06-26T17:39:46.764101Z","shell.execute_reply":"2024-06-26T17:39:47.420092Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         count unique                                                top freq\nfile     10000  10000                              allen-p/_sent_mail/1.    1\nmessage  10000  10000  Message-ID: <18782981.1075855378110.JavaMail.e...    1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>file</th>\n      <td>10000</td>\n      <td>10000</td>\n      <td>allen-p/_sent_mail/1.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>message</th>\n      <td>10000</td>\n      <td>10000</td>\n      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.rename(columns={'message': 'Body'})\ndf.head()\n\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\ndf = df.drop(['file'], axis = 1)\n\ndf = df.copy()\ndef remove_first_15_lines(text):\n    lines = text.split('\\n')\n    return '\\n'.join(lines[15:])\ndf['Body'] = df['Body'].apply(remove_first_15_lines)\n\n\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:39:47.423307Z","iopub.execute_input":"2024-06-26T17:39:47.423665Z","iopub.status.idle":"2024-06-26T17:39:47.551498Z","shell.execute_reply.started":"2024-06-26T17:39:47.423635Z","shell.execute_reply":"2024-06-26T17:39:47.550352Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Body\n0  \\nJennifer:\\n\\nMike Rabon had just forwarded t...\n1  \\nyea,  i think the two dumps in the market ar...\n2  X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...\n3  \\n  What it's trading  what I think it's reall...\n4  \\n    Thank you for requesting additional info...\n5  X-Origin: Arnold-J\\nX-FileName: Jarnold.nsf\\n\\...\n6  \\nGeorge,\\n\\n     Your attachment is not openi...\n7  \\n\\n  [IMAGE] [IMAGE] [IMAGE]  =09\\n [IMAGE]  ...\n8  \\nhttp://messages.yahoo.com/bbs?.mm=FN&action=...\n9  \\n---------------------- Forwarded by Phillip ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nJennifer:\\n\\nMike Rabon had just forwarded t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nyea,  i think the two dumps in the market ar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\n  What it's trading  what I think it's reall...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\n    Thank you for requesting additional info...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>X-Origin: Arnold-J\\nX-FileName: Jarnold.nsf\\n\\...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>\\nGeorge,\\n\\n     Your attachment is not openi...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>\\n\\n  [IMAGE] [IMAGE] [IMAGE]  =09\\n [IMAGE]  ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\\nhttp://messages.yahoo.com/bbs?.mm=FN&amp;action=...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>\\n---------------------- Forwarded by Phillip ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"The First 1 Texts:\",*df[\"Body\"][:1], sep = \"\\n_______________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:39:47.552950Z","iopub.execute_input":"2024-06-26T17:39:47.553324Z","iopub.status.idle":"2024-06-26T17:39:47.560277Z","shell.execute_reply.started":"2024-06-26T17:39:47.553295Z","shell.execute_reply":"2024-06-26T17:39:47.559049Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The First 1 Texts:\n_______________________\n\nJennifer:\n\nMike Rabon had just forwarded to me this helpful synopsis of the opportunity \nwith Kinko's as he sees it.  I would like to forward this on to James \nThompson to assist him in targeting the right person for us to work with (and \ncc Mike Rabon).  Is this a good idea to forward on the e-mail or is it \noverkill given the e-mail I sent yesterday? Second, could I mention \"Gary \nKing\" Mike Rabon's Kinko's contact in the e-mail?\n\nThanks for your suggestion!  SJ\n\n\n\n\nMr. Thompson:\n\nHere are several \"touchpoints\" identified by Mike Rabon, the Enron Broadband \nServices originator, which may facilitate your finding the appropriate \nbroadband solutions architect at Kinko's.  You may recall having met Mike \nRabon in the October 6th meeting. \n\nKinko's has an IP network today with access to all branches.  Kinko's had \nexpressed the need to add more hubs to that network and make some changes to \nit in the spring 2001 time frame.  Enron's goal would be to make a needs \nassessment for the desired structure that Kinko's would like to see as it \npertains to:\nNear term network planning.\nIP Transport - Capacity requirements for Mbps, and burst potential.\nIP Transit - Capacity requirements and current contract usage for internet \ntransit. Kinkos.com in particular has a high potential for IP transit \ncapacity.\nStorage - As the hubs and branch numbers grow, there may be a need for \nmanaged storage. Enron's solution will reduce, or eliminate the need to buy \nstorage devices. Mike Rabon would like to speak with someone at Kinko's about \nyour storage strategy and growth.\nCollocation - There is a substantial opportunity for Enron to provide the \nactual space to be used for the hubs, as well as the IP transport from the \nhubs.\nInteractive Video - Enron's IPNet Connect product will allow high quality \nH.323 video conferencing at bandwidths well above 768K. Utilizing the Enron \nIPNet Connect network installed to branches can allow video costs to be \nsignificantly reduced, and allow much higher video quality.  Enron's \nutilization of IP precedence will allow business traffic, internet traffic \nand video traffic to traverse the same network.  Mike Rabon would like to \nspeak to the Video Conferencing product manager.\nRisk Management - Enron's expertise in Risk Management needs to be \ncommunicated to the proper person.\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"data = df.copy()\ndata[\"No_of_Characters\"] = data[\"Body\"].apply(len)\ndata[\"No_of_Words\"]=data.apply(lambda row: nltk.word_tokenize(row[\"Body\"]), axis=1).apply(len)\ndata[\"No_of_sentence\"]=data.apply(lambda row: nltk.sent_tokenize(row[\"Body\"]), axis=1).apply(len)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:39:47.561712Z","iopub.execute_input":"2024-06-26T17:39:47.562053Z","iopub.status.idle":"2024-06-26T17:40:18.840543Z","shell.execute_reply.started":"2024-06-26T17:39:47.562024Z","shell.execute_reply":"2024-06-26T17:40:18.839456Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   Body  No_of_Characters  \\\n0     \\nJennifer:\\n\\nMike Rabon had just forwarded t...              2337   \n1     \\nyea,  i think the two dumps in the market ar...              3083   \n2     X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...               417   \n3     \\n  What it's trading  what I think it's reall...               974   \n4     \\n    Thank you for requesting additional info...               375   \n...                                                 ...               ...   \n9995  \\nyou think that's a valid excuse?   whatever....                48   \n9996  \\n\\n\\nHere are this week's survey results.\\n\\n...              1726   \n9997  X-bcc: \\nX-Folder: \\JARNOLD (Non-Privileged)\\A...               417   \n9998  \\n---------------------- Forwarded by Phillip ...               547   \n9999  \\nWeb server noticeably slow today.  I'm getti...               199   \n\n      No_of_Words  No_of_sentence  \n0             435              22  \n1             624              35  \n2              71               2  \n3             192               7  \n4              59               4  \n...           ...             ...  \n9995           11               2  \n9996          286              12  \n9997           65               1  \n9998          124               1  \n9999           40               3  \n\n[10000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Body</th>\n      <th>No_of_Characters</th>\n      <th>No_of_Words</th>\n      <th>No_of_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nJennifer:\\n\\nMike Rabon had just forwarded t...</td>\n      <td>2337</td>\n      <td>435</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nyea,  i think the two dumps in the market ar...</td>\n      <td>3083</td>\n      <td>624</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...</td>\n      <td>417</td>\n      <td>71</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\n  What it's trading  what I think it's reall...</td>\n      <td>974</td>\n      <td>192</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\n    Thank you for requesting additional info...</td>\n      <td>375</td>\n      <td>59</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>\\nyou think that's a valid excuse?   whatever....</td>\n      <td>48</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>\\n\\n\\nHere are this week's survey results.\\n\\n...</td>\n      <td>1726</td>\n      <td>286</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>X-bcc: \\nX-Folder: \\JARNOLD (Non-Privileged)\\A...</td>\n      <td>417</td>\n      <td>65</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>\\n---------------------- Forwarded by Phillip ...</td>\n      <td>547</td>\n      <td>124</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>\\nWeb server noticeably slow today.  I'm getti...</td>\n      <td>199</td>\n      <td>40</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def Clean(Text):\n    sms = re.sub('[^a-zA-Z]', ' ', Text) \n    sms = sms.lower() \n    sms = sms.split()\n    sms = ' '.join(sms)\n    return sms\n\ndata[\"Clean_Text\"] = data[\"Body\"].apply(Clean)\nprint(\"The First 5 Texts after cleaning:\",*data[\"Clean_Text\"][:3], sep = \"\\n___________________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:40:18.843945Z","iopub.execute_input":"2024-06-26T17:40:18.844419Z","iopub.status.idle":"2024-06-26T17:40:20.515842Z","shell.execute_reply.started":"2024-06-26T17:40:18.844378Z","shell.execute_reply":"2024-06-26T17:40:20.514687Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The First 5 Texts after cleaning:\n___________________________\njennifer mike rabon had just forwarded to me this helpful synopsis of the opportunity with kinko s as he sees it i would like to forward this on to james thompson to assist him in targeting the right person for us to work with and cc mike rabon is this a good idea to forward on the e mail or is it overkill given the e mail i sent yesterday second could i mention gary king mike rabon s kinko s contact in the e mail thanks for your suggestion sj mr thompson here are several touchpoints identified by mike rabon the enron broadband services originator which may facilitate your finding the appropriate broadband solutions architect at kinko s you may recall having met mike rabon in the october th meeting kinko s has an ip network today with access to all branches kinko s had expressed the need to add more hubs to that network and make some changes to it in the spring time frame enron s goal would be to make a needs assessment for the desired structure that kinko s would like to see as it pertains to near term network planning ip transport capacity requirements for mbps and burst potential ip transit capacity requirements and current contract usage for internet transit kinkos com in particular has a high potential for ip transit capacity storage as the hubs and branch numbers grow there may be a need for managed storage enron s solution will reduce or eliminate the need to buy storage devices mike rabon would like to speak with someone at kinko s about your storage strategy and growth collocation there is a substantial opportunity for enron to provide the actual space to be used for the hubs as well as the ip transport from the hubs interactive video enron s ipnet connect product will allow high quality h video conferencing at bandwidths well above k utilizing the enron ipnet connect network installed to branches can allow video costs to be significantly reduced and allow much higher video quality enron s utilization of ip precedence will allow business traffic internet traffic and video traffic to traverse the same network mike rabon would like to speak to the video conferencing product manager risk management enron s expertise in risk management needs to be communicated to the proper person\n___________________________\nyea i think the two dumps in the market are when everybody realizes the loss of demand which is in the first inj numbers customer buying and fear about the summer will keep may at a decent level if my theory holds eventually that wont be enough to hold the market up and m pukes second puke is in the winter when th quarter production is on y y basis demand still weak economic weakness isn t a month problem industry realizes that not only is it ok to get to bcf in march but you should and early winter weather will not match we develop large y y surplus in x and z z futures hold up because some risk premium still exists for rest of winter by late december just trying to find a home for gas think decent chance f futures finish with a handle slafontaine globalp com on pm to john arnold enron com cc subject re distillates f puts you mean january u mean june and january john arnold enron com on pm to steve lafontaine globalco globalco cc fax to subject re distillates just when i m turning really bearish you re starting to turn bullish on me weather to me relatively unimportant yes it will leave us with bcf or so less in storage than if we had mild weather i think it is masking a major demand problem think what the aga numbers would be with moderate weather when we get into injections i think we ll see a big push down spec and trade seem bearish but hesitant to get short customer buying still strong thus even with the demand picture becoming clearer we haven t moved down however i think when the picture becomes clearer i e when we start beating last year s injections by bcf a week trade will get short customers very unsophistocated the story they keep telling us is we re coming out bcf less than last year thus the summer has to be strong when we start inj customers will start seeing other side of story pira finally came out this week and said stop buying to me the mrkt just a timing issue i want to be short before the rest of the idiots get short i continue buying m f puts projecting k to settle and m slafontaine globalp com on pm to jarnold enron com cc subject distillates this strength cud persist awhile is a little bullish ngas demand since we now above parity in some places shit theres so many things shaking my faith on the short bias of this thing weather hot west cold est hydo califronia mkt talking new engl shortages oil demand cont to show stellar y on y and curve recoveriung opec hawkish stance for px support i think we close the y on y gap still significantly but im starting to question how when how much and how long prices come off in apr jun thanks god i can trade oil cuz i have made anything in ngas to speak of short term still sort of neutral ngas beleive we range bound u prob know this but hearing texas rr data coming out pretty bearish prodcution good news regards\n___________________________\nx filename pallen nsf transwestern pipeline co posted new notice s since our last check at pm the newest notice looks like capacity constraint dec pm dec am dec am allocation san juan lateral please click the following to go to the web site for detail http ios ets enron com infopostings shared et noncritical notice asp company\n","output_type":"stream"}]},{"cell_type":"code","source":"data.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:40:20.517029Z","iopub.execute_input":"2024-06-26T17:40:20.517378Z","iopub.status.idle":"2024-06-26T17:40:20.545410Z","shell.execute_reply.started":"2024-06-26T17:40:20.517350Z","shell.execute_reply":"2024-06-26T17:40:20.544347Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                    count       mean          std  min    25%    50%     75%  \\\nNo_of_Characters  10000.0  1850.3212  5971.175699  3.0  245.0  627.0  1581.0   \nNo_of_Words       10000.0   321.8975   864.275310  1.0   49.0  126.0   297.0   \nNo_of_sentence    10000.0    11.1529    25.973987  1.0    3.0    5.0    11.0   \n\n                       max  \nNo_of_Characters  125933.0  \nNo_of_Words        23324.0  \nNo_of_sentence       571.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>No_of_Characters</th>\n      <td>10000.0</td>\n      <td>1850.3212</td>\n      <td>5971.175699</td>\n      <td>3.0</td>\n      <td>245.0</td>\n      <td>627.0</td>\n      <td>1581.0</td>\n      <td>125933.0</td>\n    </tr>\n    <tr>\n      <th>No_of_Words</th>\n      <td>10000.0</td>\n      <td>321.8975</td>\n      <td>864.275310</td>\n      <td>1.0</td>\n      <td>49.0</td>\n      <td>126.0</td>\n      <td>297.0</td>\n      <td>23324.0</td>\n    </tr>\n    <tr>\n      <th>No_of_sentence</th>\n      <td>10000.0</td>\n      <td>11.1529</td>\n      <td>25.973987</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>11.0</td>\n      <td>571.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define keyword lists for each category\nshopping_keywords = [\n    'sale', 'discount', 'deal', 'offer', 'coupon', 'buy', 'purchase', 'shop',\n    'order', 'product', 'exclusive', 'bargain', 'promo', 'special', 'free',\"Sale\", \"Discount\", \"Coupon\", \"Deal\", \"Purchase\", \n    \"Order\", \"Receipt\", \"Shipping\", \"Delivery\", \"Product\", \n    \"Item\", \"Store\", \"Cart\", \"Checkout\", \"Wishlist\", \n    \"Bargain\", \"Offer\", \"Promotion\", \"Cashback\", \"Clearance\"\n]\n\nsocial_keywords = [\n    'friend', 'party', 'event', 'social', 'gathering', 'meet', 'hangout',\n    'reunion', 'celebrate', 'birthday', 'wedding', 'invite', 'fun', 'join',\"Facebook\", \"Twitter\", \"Instagram\", \"LinkedIn\", \"Friend request\", \n    \"Connection\", \"Follow\", \"Like\", \"Comment\", \"Share\", \n    \"Invite\", \"Event\", \"Group\", \"Meetup\", \"Tag\", \n    \"Message\", \"Chat\", \"Notification\", \"Timeline\", \"Post\"\n]\n\npersonal_keywords = [\n    'family', 'personal', 'update', 'life', 'news', 'home', 'kids', 'school',\n    'vacation', 'holiday', 'trip', 'hello', 'hi', 'hey', 'catch up',\"Family\", \"Friend\", \"Dinner\", \"Party\", \"Vacation\", \n    \"Trip\", \"Photos\", \"Wedding\", \"Birthday\", \"Anniversary\", \n    \"Holiday\", \"Congratulations\", \"Invitation\", \"Get-together\", \"Celebration\", \n    \"Memories\", \"Home\", \"School\", \"Love\", \"Greetings\"\n]\n\njob_keywords = [\n    'job', 'career', 'position', 'opportunity', 'interview', 'resume',\n    'application', 'hire', 'recruit', 'employment', 'work', 'office',\n    'role', 'professional', 'vacancy', \"Resume\", \"CV\", \"Interview\", \"Job offer\", \"Vacancy\", \n    \"Position\", \"Career\", \"Application\", \"Recruitment\", \"Employer\", \n    \"Hiring\", \"Opportunity\", \"Promotion\", \"Internship\", \"Work\", \n    \"Contract\", \"Full-time\", \"Part-time\", \"Freelance\", \"Job opening\"\n]\n\nnewsletter_keywords = [\n    'newsletter', 'update', 'news', 'weekly', 'monthly', 'digest', 'subscribe',\n    'issue', 'edition', 'report', 'highlights', 'bulletin', 'summary', 'email',\"Subscribe\", \"Unsubscribe\", \"Update\", \"Edition\", \"Issue\", \n    \"Bulletin\", \"Digest\", \"Weekly\", \"Monthly\", \"Newsletter\", \n    \"News\", \"Highlights\", \"Trends\", \"Insights\", \"Review\", \n    \"Recap\", \"Summary\", \"Report\", \"Announcement\", \"Special offer\",\"edition\"\n]\n\n# Initialize category columns\ndata['shopping_score'] = 0\ndata['social_score'] = 0\ndata['personal_score'] = 0\ndata['job_score'] = 0\ndata['newsletter_score'] = 0\n\n# Calculate scores based on keyword occurrences\nfor keyword in shopping_keywords:\n    data['shopping_score'] += data['Clean_Text'].str.lower().str.count(keyword.lower())\n\nfor keyword in social_keywords:\n    data['social_score'] += data['Clean_Text'].str.lower().str.count(keyword.lower())\n\nfor keyword in personal_keywords:\n    data['personal_score'] += data['Clean_Text'].str.lower().str.count(keyword.lower())\n\nfor keyword in job_keywords:\n    data['job_score'] += data['Clean_Text'].str.lower().str.count(keyword.lower())\n\nfor keyword in newsletter_keywords:\n    data['newsletter_score'] += data['Clean_Text'].str.lower().str.count(keyword.lower())\n\n# Assign categories based on the highest score\ndata['Category'] = data[['shopping_score', 'social_score', 'personal_score', 'job_score', 'newsletter_score']].idxmax(axis=1)\ndata['Category'] = data['Category'].str.replace('_score', '')\n\n# Drop the score columns\ndata = data.drop(columns=['shopping_score', 'social_score', 'personal_score', 'job_score', 'newsletter_score'])\n\n# Save the updated DataFrame to a CSV file\noutput_csv_filename = 'classified_emails.csv'\ndata.to_csv(output_csv_filename, index=False)\n\ndata['Category'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:25:26.000308Z","iopub.execute_input":"2024-06-26T18:25:26.001141Z","iopub.status.idle":"2024-06-26T18:25:35.950963Z","shell.execute_reply.started":"2024-06-26T18:25:26.001102Z","shell.execute_reply":"2024-06-26T18:25:35.949779Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"Category\npersonal      4502\nshopping      2401\nsocial        1568\njob            805\nnewsletter     724\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:25:37.363258Z","iopub.execute_input":"2024-06-26T18:25:37.363677Z","iopub.status.idle":"2024-06-26T18:25:37.385109Z","shell.execute_reply.started":"2024-06-26T18:25:37.363645Z","shell.execute_reply":"2024-06-26T18:25:37.383908Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"                                                Body  No_of_Characters  \\\n0  \\nJennifer:\\n\\nMike Rabon had just forwarded t...              2337   \n1  \\nyea,  i think the two dumps in the market ar...              3083   \n2  X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...               417   \n\n   No_of_Words  No_of_sentence  \\\n0          435              22   \n1          624              35   \n2           71               2   \n\n                                          Clean_Text  Category  \\\n0  jennifer mike rabon had just forwarded to me t...       job   \n1  yea i think the two dumps in the market are wh...  personal   \n2  x filename pallen nsf transwestern pipeline co...    social   \n\n                                       Tokenize_Text  \\\n0  [jennifer, mike, rabon, had, just, forwarded, ...   \n1  [yea, i, think, the, two, dumps, in, the, mark...   \n2  [x, filename, pallen, nsf, transwestern, pipel...   \n\n                                     Nostopword_Text  \\\n0  [jennifer, mike, rabon, forwarded, helpful, sy...   \n1  [yea, think, two, dumps, market, everybody, re...   \n2  [x, filename, pallen, nsf, transwestern, pipel...   \n\n                                        Stemmed_Text  \n0  [jennif, mike, rabon, forward, help, synopsi, ...  \n1  [yea, think, two, dump, market, everybodi, rea...  \n2  [x, filenam, pallen, nsf, transwestern, pipeli...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Body</th>\n      <th>No_of_Characters</th>\n      <th>No_of_Words</th>\n      <th>No_of_sentence</th>\n      <th>Clean_Text</th>\n      <th>Category</th>\n      <th>Tokenize_Text</th>\n      <th>Nostopword_Text</th>\n      <th>Stemmed_Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nJennifer:\\n\\nMike Rabon had just forwarded t...</td>\n      <td>2337</td>\n      <td>435</td>\n      <td>22</td>\n      <td>jennifer mike rabon had just forwarded to me t...</td>\n      <td>job</td>\n      <td>[jennifer, mike, rabon, had, just, forwarded, ...</td>\n      <td>[jennifer, mike, rabon, forwarded, helpful, sy...</td>\n      <td>[jennif, mike, rabon, forward, help, synopsi, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nyea,  i think the two dumps in the market ar...</td>\n      <td>3083</td>\n      <td>624</td>\n      <td>35</td>\n      <td>yea i think the two dumps in the market are wh...</td>\n      <td>personal</td>\n      <td>[yea, i, think, the, two, dumps, in, the, mark...</td>\n      <td>[yea, think, two, dumps, market, everybody, re...</td>\n      <td>[yea, think, two, dump, market, everybodi, rea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>X-FileName: pallen.nsf\\n\\nTranswestern Pipelin...</td>\n      <td>417</td>\n      <td>71</td>\n      <td>2</td>\n      <td>x filename pallen nsf transwestern pipeline co...</td>\n      <td>social</td>\n      <td>[x, filename, pallen, nsf, transwestern, pipel...</td>\n      <td>[x, filename, pallen, nsf, transwestern, pipel...</td>\n      <td>[x, filenam, pallen, nsf, transwestern, pipeli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['Category'].value_counts()\ncolumn = data['Category']\ndf['Category'] = column","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:26:21.747240Z","iopub.execute_input":"2024-06-26T18:26:21.747643Z","iopub.status.idle":"2024-06-26T18:26:21.755961Z","shell.execute_reply.started":"2024-06-26T18:26:21.747615Z","shell.execute_reply":"2024-06-26T18:26:21.754688Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"X = df['Body']\nY = df['Category']\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, stratify = Y ,random_state =42)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:26:22.926057Z","iopub.execute_input":"2024-06-26T18:26:22.926458Z","iopub.status.idle":"2024-06-26T18:26:22.948967Z","shell.execute_reply.started":"2024-06-26T18:26:22.926429Z","shell.execute_reply":"2024-06-26T18:26:22.947821Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"data[\"Tokenize_Text\"]=data.apply(lambda row: nltk.word_tokenize(row[\"Clean_Text\"]), axis=1)\nprint(\"The First Text after Tokenizing:\",*data[\"Tokenize_Text\"][:1], sep = \"\\n_______________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:26:23.962541Z","iopub.execute_input":"2024-06-26T18:26:23.962941Z","iopub.status.idle":"2024-06-26T18:26:34.640985Z","shell.execute_reply.started":"2024-06-26T18:26:23.962894Z","shell.execute_reply":"2024-06-26T18:26:34.639798Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"The First Text after Tokenizing:\n_______________________\n['jennifer', 'mike', 'rabon', 'had', 'just', 'forwarded', 'to', 'me', 'this', 'helpful', 'synopsis', 'of', 'the', 'opportunity', 'with', 'kinko', 's', 'as', 'he', 'sees', 'it', 'i', 'would', 'like', 'to', 'forward', 'this', 'on', 'to', 'james', 'thompson', 'to', 'assist', 'him', 'in', 'targeting', 'the', 'right', 'person', 'for', 'us', 'to', 'work', 'with', 'and', 'cc', 'mike', 'rabon', 'is', 'this', 'a', 'good', 'idea', 'to', 'forward', 'on', 'the', 'e', 'mail', 'or', 'is', 'it', 'overkill', 'given', 'the', 'e', 'mail', 'i', 'sent', 'yesterday', 'second', 'could', 'i', 'mention', 'gary', 'king', 'mike', 'rabon', 's', 'kinko', 's', 'contact', 'in', 'the', 'e', 'mail', 'thanks', 'for', 'your', 'suggestion', 'sj', 'mr', 'thompson', 'here', 'are', 'several', 'touchpoints', 'identified', 'by', 'mike', 'rabon', 'the', 'enron', 'broadband', 'services', 'originator', 'which', 'may', 'facilitate', 'your', 'finding', 'the', 'appropriate', 'broadband', 'solutions', 'architect', 'at', 'kinko', 's', 'you', 'may', 'recall', 'having', 'met', 'mike', 'rabon', 'in', 'the', 'october', 'th', 'meeting', 'kinko', 's', 'has', 'an', 'ip', 'network', 'today', 'with', 'access', 'to', 'all', 'branches', 'kinko', 's', 'had', 'expressed', 'the', 'need', 'to', 'add', 'more', 'hubs', 'to', 'that', 'network', 'and', 'make', 'some', 'changes', 'to', 'it', 'in', 'the', 'spring', 'time', 'frame', 'enron', 's', 'goal', 'would', 'be', 'to', 'make', 'a', 'needs', 'assessment', 'for', 'the', 'desired', 'structure', 'that', 'kinko', 's', 'would', 'like', 'to', 'see', 'as', 'it', 'pertains', 'to', 'near', 'term', 'network', 'planning', 'ip', 'transport', 'capacity', 'requirements', 'for', 'mbps', 'and', 'burst', 'potential', 'ip', 'transit', 'capacity', 'requirements', 'and', 'current', 'contract', 'usage', 'for', 'internet', 'transit', 'kinkos', 'com', 'in', 'particular', 'has', 'a', 'high', 'potential', 'for', 'ip', 'transit', 'capacity', 'storage', 'as', 'the', 'hubs', 'and', 'branch', 'numbers', 'grow', 'there', 'may', 'be', 'a', 'need', 'for', 'managed', 'storage', 'enron', 's', 'solution', 'will', 'reduce', 'or', 'eliminate', 'the', 'need', 'to', 'buy', 'storage', 'devices', 'mike', 'rabon', 'would', 'like', 'to', 'speak', 'with', 'someone', 'at', 'kinko', 's', 'about', 'your', 'storage', 'strategy', 'and', 'growth', 'collocation', 'there', 'is', 'a', 'substantial', 'opportunity', 'for', 'enron', 'to', 'provide', 'the', 'actual', 'space', 'to', 'be', 'used', 'for', 'the', 'hubs', 'as', 'well', 'as', 'the', 'ip', 'transport', 'from', 'the', 'hubs', 'interactive', 'video', 'enron', 's', 'ipnet', 'connect', 'product', 'will', 'allow', 'high', 'quality', 'h', 'video', 'conferencing', 'at', 'bandwidths', 'well', 'above', 'k', 'utilizing', 'the', 'enron', 'ipnet', 'connect', 'network', 'installed', 'to', 'branches', 'can', 'allow', 'video', 'costs', 'to', 'be', 'significantly', 'reduced', 'and', 'allow', 'much', 'higher', 'video', 'quality', 'enron', 's', 'utilization', 'of', 'ip', 'precedence', 'will', 'allow', 'business', 'traffic', 'internet', 'traffic', 'and', 'video', 'traffic', 'to', 'traverse', 'the', 'same', 'network', 'mike', 'rabon', 'would', 'like', 'to', 'speak', 'to', 'the', 'video', 'conferencing', 'product', 'manager', 'risk', 'management', 'enron', 's', 'expertise', 'in', 'risk', 'management', 'needs', 'to', 'be', 'communicated', 'to', 'the', 'proper', 'person']\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_stopwords(text):\n    stop_words = set(stopwords.words(\"english\"))\n    filtered_text = [word for word in text if word not in stop_words]\n    return filtered_text\n\ndata[\"Nostopword_Text\"] = data[\"Tokenize_Text\"].apply(remove_stopwords)\n\nprint(\"The First Text after removing the stopwords: \",*data[\"Nostopword_Text\"][:1], sep = \"\\n____________________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:26:34.642835Z","iopub.execute_input":"2024-06-26T18:26:34.643255Z","iopub.status.idle":"2024-06-26T18:26:36.353420Z","shell.execute_reply.started":"2024-06-26T18:26:34.643225Z","shell.execute_reply":"2024-06-26T18:26:36.352240Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"The First Text after removing the stopwords: \n____________________________\n['jennifer', 'mike', 'rabon', 'forwarded', 'helpful', 'synopsis', 'opportunity', 'kinko', 'sees', 'would', 'like', 'forward', 'james', 'thompson', 'assist', 'targeting', 'right', 'person', 'us', 'work', 'cc', 'mike', 'rabon', 'good', 'idea', 'forward', 'e', 'mail', 'overkill', 'given', 'e', 'mail', 'sent', 'yesterday', 'second', 'could', 'mention', 'gary', 'king', 'mike', 'rabon', 'kinko', 'contact', 'e', 'mail', 'thanks', 'suggestion', 'sj', 'mr', 'thompson', 'several', 'touchpoints', 'identified', 'mike', 'rabon', 'enron', 'broadband', 'services', 'originator', 'may', 'facilitate', 'finding', 'appropriate', 'broadband', 'solutions', 'architect', 'kinko', 'may', 'recall', 'met', 'mike', 'rabon', 'october', 'th', 'meeting', 'kinko', 'ip', 'network', 'today', 'access', 'branches', 'kinko', 'expressed', 'need', 'add', 'hubs', 'network', 'make', 'changes', 'spring', 'time', 'frame', 'enron', 'goal', 'would', 'make', 'needs', 'assessment', 'desired', 'structure', 'kinko', 'would', 'like', 'see', 'pertains', 'near', 'term', 'network', 'planning', 'ip', 'transport', 'capacity', 'requirements', 'mbps', 'burst', 'potential', 'ip', 'transit', 'capacity', 'requirements', 'current', 'contract', 'usage', 'internet', 'transit', 'kinkos', 'com', 'particular', 'high', 'potential', 'ip', 'transit', 'capacity', 'storage', 'hubs', 'branch', 'numbers', 'grow', 'may', 'need', 'managed', 'storage', 'enron', 'solution', 'reduce', 'eliminate', 'need', 'buy', 'storage', 'devices', 'mike', 'rabon', 'would', 'like', 'speak', 'someone', 'kinko', 'storage', 'strategy', 'growth', 'collocation', 'substantial', 'opportunity', 'enron', 'provide', 'actual', 'space', 'used', 'hubs', 'well', 'ip', 'transport', 'hubs', 'interactive', 'video', 'enron', 'ipnet', 'connect', 'product', 'allow', 'high', 'quality', 'h', 'video', 'conferencing', 'bandwidths', 'well', 'k', 'utilizing', 'enron', 'ipnet', 'connect', 'network', 'installed', 'branches', 'allow', 'video', 'costs', 'significantly', 'reduced', 'allow', 'much', 'higher', 'video', 'quality', 'enron', 'utilization', 'ip', 'precedence', 'allow', 'business', 'traffic', 'internet', 'traffic', 'video', 'traffic', 'traverse', 'network', 'mike', 'rabon', 'would', 'like', 'speak', 'video', 'conferencing', 'product', 'manager', 'risk', 'management', 'enron', 'expertise', 'risk', 'management', 'needs', 'communicated', 'proper', 'person']\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\ndef stem_text(text):\n    stemmed_words = [stemmer.stem(word) for word in text]\n    return stemmed_words\n\ndata[\"Stemmed_Text\"] = data[\"Nostopword_Text\"].apply(stem_text)\nprint(\"The First Text after removing the stopwords: \",*data[\"Stemmed_Text\"][:1], sep = \"\\n____________________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:26:36.354899Z","iopub.execute_input":"2024-06-26T18:26:36.355298Z","iopub.status.idle":"2024-06-26T18:27:18.294648Z","shell.execute_reply.started":"2024-06-26T18:26:36.355271Z","shell.execute_reply":"2024-06-26T18:27:18.293529Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"The First Text after removing the stopwords: \n____________________________\n['jennif', 'mike', 'rabon', 'forward', 'help', 'synopsi', 'opportun', 'kinko', 'see', 'would', 'like', 'forward', 'jame', 'thompson', 'assist', 'target', 'right', 'person', 'us', 'work', 'cc', 'mike', 'rabon', 'good', 'idea', 'forward', 'e', 'mail', 'overkil', 'given', 'e', 'mail', 'sent', 'yesterday', 'second', 'could', 'mention', 'gari', 'king', 'mike', 'rabon', 'kinko', 'contact', 'e', 'mail', 'thank', 'suggest', 'sj', 'mr', 'thompson', 'sever', 'touchpoint', 'identifi', 'mike', 'rabon', 'enron', 'broadband', 'servic', 'origin', 'may', 'facilit', 'find', 'appropri', 'broadband', 'solut', 'architect', 'kinko', 'may', 'recal', 'met', 'mike', 'rabon', 'octob', 'th', 'meet', 'kinko', 'ip', 'network', 'today', 'access', 'branch', 'kinko', 'express', 'need', 'add', 'hub', 'network', 'make', 'chang', 'spring', 'time', 'frame', 'enron', 'goal', 'would', 'make', 'need', 'assess', 'desir', 'structur', 'kinko', 'would', 'like', 'see', 'pertain', 'near', 'term', 'network', 'plan', 'ip', 'transport', 'capac', 'requir', 'mbp', 'burst', 'potenti', 'ip', 'transit', 'capac', 'requir', 'current', 'contract', 'usag', 'internet', 'transit', 'kinko', 'com', 'particular', 'high', 'potenti', 'ip', 'transit', 'capac', 'storag', 'hub', 'branch', 'number', 'grow', 'may', 'need', 'manag', 'storag', 'enron', 'solut', 'reduc', 'elimin', 'need', 'buy', 'storag', 'devic', 'mike', 'rabon', 'would', 'like', 'speak', 'someon', 'kinko', 'storag', 'strategi', 'growth', 'colloc', 'substanti', 'opportun', 'enron', 'provid', 'actual', 'space', 'use', 'hub', 'well', 'ip', 'transport', 'hub', 'interact', 'video', 'enron', 'ipnet', 'connect', 'product', 'allow', 'high', 'qualiti', 'h', 'video', 'conferenc', 'bandwidth', 'well', 'k', 'util', 'enron', 'ipnet', 'connect', 'network', 'instal', 'branch', 'allow', 'video', 'cost', 'significantli', 'reduc', 'allow', 'much', 'higher', 'video', 'qualiti', 'enron', 'util', 'ip', 'preced', 'allow', 'busi', 'traffic', 'internet', 'traffic', 'video', 'traffic', 'travers', 'network', 'mike', 'rabon', 'would', 'like', 'speak', 'video', 'conferenc', 'product', 'manag', 'risk', 'manag', 'enron', 'expertis', 'risk', 'manag', 'need', 'commun', 'proper', 'person']\n","output_type":"stream"}]},{"cell_type":"code","source":"corpus = data[\"Stemmed_Text\"].apply(lambda x: ' '.join(x)).tolist()\ncorpus[:5]\nprint(\"The First 5 lines in corpus \",*corpus[:5], sep = \"\\n___________________________\\n\")\nprint(type(corpus))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:27:18.296807Z","iopub.execute_input":"2024-06-26T18:27:18.297161Z","iopub.status.idle":"2024-06-26T18:27:18.360792Z","shell.execute_reply.started":"2024-06-26T18:27:18.297130Z","shell.execute_reply":"2024-06-26T18:27:18.359689Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"The First 5 lines in corpus \n___________________________\njennif mike rabon forward help synopsi opportun kinko see would like forward jame thompson assist target right person us work cc mike rabon good idea forward e mail overkil given e mail sent yesterday second could mention gari king mike rabon kinko contact e mail thank suggest sj mr thompson sever touchpoint identifi mike rabon enron broadband servic origin may facilit find appropri broadband solut architect kinko may recal met mike rabon octob th meet kinko ip network today access branch kinko express need add hub network make chang spring time frame enron goal would make need assess desir structur kinko would like see pertain near term network plan ip transport capac requir mbp burst potenti ip transit capac requir current contract usag internet transit kinko com particular high potenti ip transit capac storag hub branch number grow may need manag storag enron solut reduc elimin need buy storag devic mike rabon would like speak someon kinko storag strategi growth colloc substanti opportun enron provid actual space use hub well ip transport hub interact video enron ipnet connect product allow high qualiti h video conferenc bandwidth well k util enron ipnet connect network instal branch allow video cost significantli reduc allow much higher video qualiti enron util ip preced allow busi traffic internet traffic video traffic travers network mike rabon would like speak video conferenc product manag risk manag enron expertis risk manag need commun proper person\n___________________________\nyea think two dump market everybodi realiz loss demand first inj number custom buy fear summer keep may decent level theori hold eventu wont enough hold market puke second puke winter th quarter product basi demand still weak econom weak month problem industri realiz ok get bcf march earli winter weather match develop larg surplu x z z futur hold risk premium still exist rest winter late decemb tri find home ga think decent chanc f futur finish handl slafontain globalp com pm john arnold enron com cc subject distil f put mean januari u mean june januari john arnold enron com pm steve lafontain globalco globalco cc fax subject distil turn realli bearish start turn bullish weather rel unimport ye leav us bcf less storag mild weather think mask major demand problem think aga number would moder weather get inject think see big push spec trade seem bearish hesit get short custom buy still strong thu even demand pictur becom clearer move howev think pictur becom clearer e start beat last year inject bcf week trade get short custom unsophistoc stori keep tell us come bcf less last year thu summer strong start inj custom start see side stori pira final came week said stop buy mrkt time issu want short rest idiot get short continu buy f put project k settl slafontain globalp com pm jarnold enron com cc subject distil strength cud persist awhil littl bullish nga demand sinc pariti place shit there mani thing shake faith short bia thing weather hot west cold est hydo califronia mkt talk new engl shortag oil demand cont show stellar curv recoveriung opec hawkish stanc px support think close gap still significantli im start question much long price come apr jun thank god trade oil cuz made anyth nga speak short term still sort neutral nga beleiv rang bound u prob know hear texa rr data come pretti bearish prodcut good news regard\n___________________________\nx filenam pallen nsf transwestern pipelin co post new notic sinc last check pm newest notic look like capac constraint dec pm dec dec alloc san juan later pleas click follow go web site detail http io et enron com infopost share et noncrit notic asp compani\n___________________________\ntrade think realli worth apr oct nov mar cal cal obvious bearish go howev game right sell hold although soon game tomorrow next week next month market structur short term ga thank friend california ca buy power william calpin dynegi dont care ga cost irrelev term go short term unless front come scare produc start hedg el paso find fix price lng tune day year jennif fraser enron enronxg john arnold hou ect ect cc subject thought ap oct nov mar price level outlook thank jen fraser\n___________________________\nthank request addit inform creat valu financi manag download inform go follow link link span one line pleas past entir link browser window http wh exec wharton upenn edu cfmtest prog info cfm program oe dfm pcode\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidf = TfidfVectorizer()\nempty_array = np.empty((10000, 32355))\n\nX = tfidf.fit_transform(corpus).toarray()\n#Let's have a look at our feature \nX","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:27:28.127623Z","iopub.execute_input":"2024-06-26T18:27:28.128403Z","iopub.status.idle":"2024-06-26T18:27:32.787502Z","shell.execute_reply.started":"2024-06-26T18:27:28.128367Z","shell.execute_reply":"2024-06-26T18:27:32.786422Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf[\"Category\"] = label_encoder.fit_transform(df[\"Category\"])\ndf['Category'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:28:05.017716Z","iopub.execute_input":"2024-06-26T18:28:05.018120Z","iopub.status.idle":"2024-06-26T18:28:05.032645Z","shell.execute_reply.started":"2024-06-26T18:28:05.018090Z","shell.execute_reply":"2024-06-26T18:28:05.031377Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"Category\n2    4502\n3    2401\n4    1568\n0     805\n1     724\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"Y = df['Category']\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, stratify = Y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:28:06.622870Z","iopub.execute_input":"2024-06-26T18:28:06.623601Z","iopub.status.idle":"2024-06-26T18:28:08.413469Z","shell.execute_reply.started":"2024-06-26T18:28:06.623557Z","shell.execute_reply":"2024-06-26T18:28:08.412359Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\n\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:28:37.539888Z","iopub.execute_input":"2024-06-26T18:28:37.540308Z","iopub.status.idle":"2024-06-26T18:28:37.547546Z","shell.execute_reply.started":"2024-06-26T18:28:37.540275Z","shell.execute_reply":"2024-06-26T18:28:37.546254Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# defining the model\nmodel = Sequential()\n\n# adding input layer\nmodel.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n\n# adding hidden layers\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(Y_train.shape[1], activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:28:40.011078Z","iopub.execute_input":"2024-06-26T18:28:40.011489Z","iopub.status.idle":"2024-06-26T18:28:40.104959Z","shell.execute_reply.started":"2024-06-26T18:28:40.011461Z","shell.execute_reply":"2024-06-26T18:28:40.103857Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20, batch_size=32, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:28:44.187663Z","iopub.execute_input":"2024-06-26T18:28:44.188087Z","iopub.status.idle":"2024-06-26T18:31:18.449762Z","shell.execute_reply.started":"2024-06-26T18:28:44.188052Z","shell.execute_reply":"2024-06-26T18:31:18.448342Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4458 - loss: 1.3911 - val_accuracy: 0.7287 - val_loss: 0.7407\nEpoch 2/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7891 - loss: 0.6181 - val_accuracy: 0.8653 - val_loss: 0.4776\nEpoch 3/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9194 - loss: 0.2670 - val_accuracy: 0.8807 - val_loss: 0.4808\nEpoch 4/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9538 - loss: 0.1700 - val_accuracy: 0.8970 - val_loss: 0.4611\nEpoch 5/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9636 - loss: 0.1204 - val_accuracy: 0.8980 - val_loss: 0.5148\nEpoch 6/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9774 - loss: 0.0833 - val_accuracy: 0.8910 - val_loss: 0.5663\nEpoch 7/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9820 - loss: 0.0748 - val_accuracy: 0.8940 - val_loss: 0.6056\nEpoch 8/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9836 - loss: 0.0660 - val_accuracy: 0.8970 - val_loss: 0.6429\nEpoch 9/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9820 - loss: 0.0628 - val_accuracy: 0.8890 - val_loss: 0.6717\nEpoch 10/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9810 - loss: 0.0619 - val_accuracy: 0.8907 - val_loss: 0.6840\nEpoch 11/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9848 - loss: 0.0575 - val_accuracy: 0.8983 - val_loss: 0.7073\nEpoch 12/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9911 - loss: 0.0359 - val_accuracy: 0.8943 - val_loss: 0.7958\nEpoch 13/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9880 - loss: 0.0365 - val_accuracy: 0.8967 - val_loss: 0.8352\nEpoch 14/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9907 - loss: 0.0351 - val_accuracy: 0.8953 - val_loss: 0.8692\nEpoch 15/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9878 - loss: 0.0440 - val_accuracy: 0.8943 - val_loss: 0.7830\nEpoch 16/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9860 - loss: 0.0590 - val_accuracy: 0.8920 - val_loss: 0.8758\nEpoch 17/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9870 - loss: 0.0498 - val_accuracy: 0.8947 - val_loss: 0.8384\nEpoch 18/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0316 - val_accuracy: 0.8940 - val_loss: 0.9314\nEpoch 19/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9901 - loss: 0.0357 - val_accuracy: 0.8917 - val_loss: 0.9027\nEpoch 20/20\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9918 - loss: 0.0246 - val_accuracy: 0.8950 - val_loss: 1.0419\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\nprint(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:31:54.577660Z","iopub.execute_input":"2024-06-26T18:31:54.578118Z","iopub.status.idle":"2024-06-26T18:31:55.956114Z","shell.execute_reply.started":"2024-06-26T18:31:54.578083Z","shell.execute_reply":"2024-06-26T18:31:55.954884Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Loss: 1.0419, Accuracy: 0.8950\n","output_type":"stream"}]},{"cell_type":"code","source":"Y_pred = model.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis=1)\nY_test_classes = np.argmax(Y_test, axis=1)\n\nprint(f'Predicted classes: {Y_pred_classes[:100]}')\nprint(f'True classes: {Y_test_classes[:100]}')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:31:58.721938Z","iopub.execute_input":"2024-06-26T18:31:58.722373Z","iopub.status.idle":"2024-06-26T18:32:00.135622Z","shell.execute_reply.started":"2024-06-26T18:31:58.722339Z","shell.execute_reply":"2024-06-26T18:32:00.134294Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\nPredicted classes: [2 2 0 0 3 4 2 2 2 2 1 4 2 2 2 2 2 4 2 0 2 2 2 2 2 2 2 2 2 0 1 2 2 2 2 3 3\n 2 3 3 3 4 2 0 2 0 3 2 2 2 2 4 2 1 2 0 3 4 3 2 4 3 2 0 3 3 2 0 2 2 4 2 3 2\n 2 1 2 2 2 2 2 1 2 4 2 3 2 0 1 2 3 2 1 2 2 3 4 3 2 3]\nTrue classes: [2 2 0 0 3 4 2 2 2 2 1 4 2 2 2 2 2 4 2 0 2 2 2 2 2 2 2 2 2 0 1 2 2 2 2 3 3\n 2 3 3 3 4 2 0 2 2 3 2 2 3 3 4 2 1 2 0 3 4 3 2 4 3 2 0 3 3 0 0 2 2 4 2 3 2\n 2 1 2 2 3 2 2 1 2 4 2 3 2 0 1 2 3 2 1 2 2 3 4 3 2 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"this is the upgraded edition of DailyDoseOfInternet. Happy reading!\"\ndef predict_category(text):\n    text = Clean(text)\n    text = nltk.word_tokenize(text)\n    text = remove_stopwords(text)\n    text = stem_text(text)\n\n    msg = ' '.join(text)\n    x = tfidf.transform([msg]).toarray()  # Use transform instead of fit_transform\n    y_pred = model.predict(x)\n    y_pred_class = np.argmax(y_pred, axis=1)\n\n    return label_encoder.inverse_transform(y_pred_class)[0]\n\npredicted_category = predict_category(text)\nprint(f'Predicted category: {predicted_category}')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:33:34.997701Z","iopub.execute_input":"2024-06-26T18:33:34.998552Z","iopub.status.idle":"2024-06-26T18:33:35.093644Z","shell.execute_reply.started":"2024-06-26T18:33:34.998516Z","shell.execute_reply":"2024-06-26T18:33:35.092582Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\nPredicted category: newsletter\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:11:51.779010Z","iopub.execute_input":"2024-06-26T18:11:51.779447Z","iopub.status.idle":"2024-06-26T18:11:51.888659Z","shell.execute_reply.started":"2024-06-26T18:11:51.779414Z","shell.execute_reply":"2024-06-26T18:11:51.887561Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}